#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyse Exploratoire des DonnÃ©es (EDA)
Projet BI - PanthÃ©on-Sorbonne Data Analytics
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration
plt.style.use('seaborn-v0_8-darkgrid')
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

class DataExplorer:
    """Classe pour l'analyse exploratoire des donnÃ©es"""
    
    def __init__(self, data_path='01_data/raw/'):
        self.data_path = data_path
        self.dataframes = {}
        self.load_data()
        
    def load_data(self):
        """Charger tous les fichiers CSV"""
        print("=" * 80)
        print("CHARGEMENT DES DONNÃ‰ES")
        print("=" * 80)
        
        files = {
            'ventes': 'ventes.csv',
            'produits': 'produits.csv',
            'categories': 'categories.csv',
            'enseignes': 'enseignes.csv'
        }
        
        for name, file in files.items():
            try:
                df = pd.read_csv(f"{self.data_path}{file}")
                self.dataframes[name] = df
                print(f"âœ… {name}: {len(df)} lignes, {len(df.columns)} colonnes")
            except Exception as e:
                print(f"âŒ Erreur lors du chargement de {file}: {e}")
                
    def basic_info(self):
        """Informations basiques sur chaque dataset"""
        print("\n" + "=" * 80)
        print("INFORMATIONS GÃ‰NÃ‰RALES")
        print("=" * 80)
        
        for name, df in self.dataframes.items():
            print(f"\nğŸ“Š DATASET: {name.upper()}")
            print("-" * 40)
            print(f"Dimensions: {df.shape}")
            print(f"Colonnes: {list(df.columns)}")
            print(f"Types de donnÃ©es:")
            print(df.dtypes)
            print(f"\nValeurs manquantes:")
            print(df.isnull().sum())
            print(f"\nPremiÃ¨res lignes:")
            print(df.head(3))
            
    def data_quality_check(self):
        """VÃ©rification de la qualitÃ© des donnÃ©es"""
        print("\n" + "=" * 80)
        print("CONTRÃ”LE QUALITÃ‰ DES DONNÃ‰ES")
        print("=" * 80)
        
        issues = []
        
        # VÃ©rifier les ventes
        if 'ventes' in self.dataframes:
            ventes = self.dataframes['ventes']
            
            # Doublons
            duplicates = ventes.duplicated().sum()
            if duplicates > 0:
                issues.append(f"âš ï¸ {duplicates} doublons dans les ventes")
            
            # Dates invalides
            try:
                ventes['Date_vente'] = pd.to_datetime(ventes['Date_vente'])
                date_range = f"{ventes['Date_vente'].min()} Ã  {ventes['Date_vente'].max()}"
                print(f"ğŸ“… PÃ©riode des ventes: {date_range}")
            except:
                issues.append("âš ï¸ ProblÃ¨me avec les dates de vente")
            
            # Prix nÃ©gatifs
            if 'Prix Total' in ventes.columns:
                negative_prices = (ventes['Prix Total'] < 0).sum()
                if negative_prices > 0:
                    issues.append(f"âš ï¸ {negative_prices} prix nÃ©gatifs")
                    
        # VÃ©rifier l'intÃ©gritÃ© rÃ©fÃ©rentielle
        if 'ventes' in self.dataframes and 'produits' in self.dataframes:
            ventes = self.dataframes['ventes']
            produits = self.dataframes['produits']
            
            # Produits orphelins
            ventes_products = set(ventes['Reference Produit'].unique())
            available_products = set(produits['Reference_Produit'].unique())
            orphans = ventes_products - available_products
            
            if orphans:
                issues.append(f"âš ï¸ {len(orphans)} rÃ©fÃ©rences produits introuvables")
                
        if issues:
            print("\nğŸ”´ ProblÃ¨mes dÃ©tectÃ©s:")
            for issue in issues:
                print(f"  {issue}")
        else:
            print("\nâœ… Aucun problÃ¨me majeur dÃ©tectÃ©!")
            
    def statistical_summary(self):
        """RÃ©sumÃ© statistique des donnÃ©es numÃ©riques"""
        print("\n" + "=" * 80)
        print("RÃ‰SUMÃ‰ STATISTIQUE")
        print("=" * 80)
        
        if 'ventes' in self.dataframes:
            ventes = self.dataframes['ventes']
            
            print("\nğŸ“ˆ Statistiques des Ventes:")
            print("-" * 40)
            
            # Convertir la date
            ventes['Date_vente'] = pd.to_datetime(ventes['Date_vente'])
            
            # Statistiques gÃ©nÃ©rales
            total_revenue = ventes['Prix Total'].sum()
            avg_transaction = ventes['Prix Total'].mean()
            total_quantity = ventes['Quantite'].sum()
            avg_quantity = ventes['Quantite'].mean()
            
            print(f"ğŸ’° Chiffre d'affaires total: {total_revenue:,.2f} â‚¬")
            print(f"ğŸ“Š Nombre de transactions: {len(ventes)}")
            print(f"ğŸ’µ Panier moyen: {avg_transaction:.2f} â‚¬")
            print(f"ğŸ“¦ QuantitÃ© totale vendue: {total_quantity:,.0f}")
            print(f"ğŸ“¦ QuantitÃ© moyenne par transaction: {avg_quantity:.2f}")
            
            # Top 5 enseignes
            print("\nğŸª Top 5 Enseignes par CA:")
            top_stores = ventes.groupby('Enseigne')['Prix Total'].sum().sort_values(ascending=False).head()
            for store, revenue in top_stores.items():
                print(f"  {store}: {revenue:,.2f} â‚¬")
            
            # Analyse temporelle
            print("\nğŸ“… Analyse Temporelle:")
            ventes['Year'] = ventes['Date_vente'].dt.year
            ventes['Month'] = ventes['Date_vente'].dt.month
            yearly_sales = ventes.groupby('Year')['Prix Total'].sum()
            for year, revenue in yearly_sales.items():
                print(f"  {year}: {revenue:,.2f} â‚¬")
                
    def generate_insights(self):
        """GÃ©nÃ©rer des insights automatiques"""
        print("\n" + "=" * 80)
        print("INSIGHTS CLÃ‰S")
        print("=" * 80)
        
        insights = []
        
        if 'ventes' in self.dataframes:
            ventes = self.dataframes['ventes']
            ventes['Date_vente'] = pd.to_datetime(ventes['Date_vente'])
            
            # Meilleur mois
            ventes['YearMonth'] = ventes['Date_vente'].dt.to_period('M')
            best_month = ventes.groupby('YearMonth')['Prix Total'].sum().idxmax()
            best_month_revenue = ventes.groupby('YearMonth')['Prix Total'].sum().max()
            insights.append(f"ğŸ“ˆ Meilleur mois: {best_month} ({best_month_revenue:,.2f} â‚¬)")
            
            # Produit star
            if 'produits' in self.dataframes:
                ventes_with_products = ventes.merge(
                    self.dataframes['produits'], 
                    left_on='Reference Produit', 
                    right_on='Reference_Produit',
                    how='left'
                )
                if 'Nom' in ventes_with_products.columns:
                    top_product = ventes_with_products.groupby('Nom')['Prix Total'].sum().idxmax()
                    top_product_revenue = ventes_with_products.groupby('Nom')['Prix Total'].sum().max()
                    insights.append(f"â­ Produit star: {top_product} ({top_product_revenue:,.2f} â‚¬)")
            
            # Concentration des ventes
            top20_products = ventes.groupby('Reference Produit')['Prix Total'].sum().nlargest(20).sum()
            total_revenue = ventes['Prix Total'].sum()
            concentration = (top20_products / total_revenue) * 100
            insights.append(f"ğŸ¯ Les 20 meilleurs produits = {concentration:.1f}% du CA")
            
            # SaisonnalitÃ©
            ventes['Quarter'] = ventes['Date_vente'].dt.quarter
            q4_sales = ventes[ventes['Quarter'] == 4]['Prix Total'].sum()
            q4_percent = (q4_sales / total_revenue) * 100
            insights.append(f"ğŸ„ Q4 reprÃ©sente {q4_percent:.1f}% des ventes annuelles")
            
        print("\nğŸ’¡ Insights dÃ©couverts:")
        for i, insight in enumerate(insights, 1):
            print(f"{i}. {insight}")
            
    def export_summary(self):
        """Exporter un rÃ©sumÃ© de l'analyse"""
        summary = {
            'date_analyse': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'datasets': {}
        }
        
        for name, df in self.dataframes.items():
            summary['datasets'][name] = {
                'rows': len(df),
                'columns': len(df.columns),
                'missing_values': df.isnull().sum().sum(),
                'duplicates': df.duplicated().sum()
            }
            
        # Sauvegarder le rÃ©sumÃ©
        import json
        with open('01_data/processed/eda_summary.json', 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
            
        print("\nâœ… RÃ©sumÃ© exportÃ© vers: 01_data/processed/eda_summary.json")
        
    def run_complete_analysis(self):
        """ExÃ©cuter l'analyse complÃ¨te"""
        print("\n" + "ğŸ” ANALYSE EXPLORATOIRE DES DONNÃ‰ES " + "ğŸ”")
        print("Projet BI - PanthÃ©on-Sorbonne")
        print("=" * 80)
        
        self.basic_info()
        self.data_quality_check()
        self.statistical_summary()
        self.generate_insights()
        
        print("\n" + "=" * 80)
        print("ANALYSE TERMINÃ‰E AVEC SUCCÃˆS âœ…")
        print("=" * 80)


def main():
    """Fonction principale"""
    # Note: Ajuster le chemin selon votre structure
    explorer = DataExplorer(data_path='/mnt/project/')
    explorer.run_complete_analysis()
    
    # Pour exporter le rÃ©sumÃ© (crÃ©er d'abord les dossiers)
    # explorer.export_summary()


if __name__ == "__main__":
    main()
